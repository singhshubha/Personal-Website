---
title: "Application for Clearwater Analytics" 
author: "Shubha Swarnim Singh"
editor: visual
format:
  html:
    embed-resources: true
---

This is a dataset that i used while i took CSC Data Visualization. i have followed up with few models to predict the number of streams for each song in the test dataset based on the features: Danceability, Energy, Loudness, Speechiness, Acousticness, and Duration_min. I goggled a little bit about how we can create a perfect model for this kind of dataset. One way was to LASSO and use a Linear regression after was the answer. It was because LASSO reduces the complexity of the model if we have different variables and Linear regression uses ht best impacting variable to predict the model. After then i also used Linear gradient model and compared it with the previous one and used the best one on test set.

# Libraries

Installing all the necessary libraries for my project.

```{r}
library(readr)
library(dplyr)
library(knitr)
library(tidyverse)
library(tidymodels)
library(caret)
library(ISLR2)
library(readODS)
library(ggrepel)
library(glmnet)

tidymodels_prefer()
```

# Introduction

I took the Spotify data set for my final project. The data set provides details on several tracks by the artists, featuring columns like "Artist," "Track," "Album," and numeric values reflecting characteristics of each song. Notably, the dataset includes attributes such as dance ability, energy, loudness, speechiness, acoustics, and duration. Each row corresponds to a specific track, with associated quantitative metrics offering insights into the musical features of different songs.\
The variables used in this dataset are:

-   **Artist**: The name of the musician or band that performed the track.

-   **Track**: The title of the song.

-   **Album**: The name of the album in which the track is included.

-   **Album_type**: The category of the album, such as single, EP, or full-length album.

-   **Danceability**: A numerical measure of how suitable the track is for dancing.

-   **Energy**: A measure of the intensity and activity level of the track.

-   **Loudness**: The overall volume level of the track in decibels.

-   **Speechiness**: A measure of the amount of spoken words in the track.

-   **Acousticness**: A measure indicating the likelihood of the track being acoustic.

-   **Instrumentalness**: A measure of the absence of vocals in the track.

-   **Liveness**: A measure indicating the probability of the track being recorded live.

-   **Valence**: A measure of how positive or happy the track sounds.

-   **Tempo**: The speed of the track, measured in beats per minute (BPM).

-   **Duration_min**: The length of the track in minutes.

-   **Title**: The official name or title of the track.

-   **Channel**: The platform or YouTube channel where the track is published.

-   **Views**: The total number of times the track has been viewed.

-   **Likes**: The number of likes the track has received.

-   **Comments**: The number of comments on the track.

-   **Licensed**: Indicates whether the track is officially licensed.

-   **Official_video**: Specifies whether the track has an official music video.

-   **Stream**: The total number of times the track has been streamed on platforms like Spotify.

-   **EnergyLiveness**: A combined metric that measures both the intensity and live presence of the track.

-   **Most_playedon**: The platform where the track has been played the most.

The reason for me to choose this project was because a lot of us in the intro presentation wrote about music history and what kind of music we love. Therefore, I thought it would be an interesting topic to show to the class because most of us will be actively engaged throughout the presentation process. The first problem that I had was the space. the file was over 5 MB, and R Studio does not allow any files larger than 5 MB. Therefore, I had to manually remove some of the unwanted columns from the data set before I loaded it into the server. Here, Unwanted columns are those which do not contribute to the graph like acoustics of the song or time duration of the song.

## Data processing

```{r}
#reading the data set
spotify <- read_csv("~/Downloads/spotify_dataset.csv")
spotify <- spotify |>
  drop_na()

# Identify columns with zero variance
zero_var_cols <- spotify |>
  summarise(across(everything(), sd, na.rm = TRUE)) |>
  select_if(~ . == 0) |>
  names()

# Remove columns with zero variance
spotify_data <- spotify |>
  select(-all_of(zero_var_cols))

head(spotify_data)

```

The wrangling process is done. Everything has been cleared and it is ready to be used for data analysis. the dataset now can be used in interpreting and visualizing graphs.

Now, we are visualizing the graph that will provide people with appropriate information and they can learn from it too. This graph represents the danceability of songs which means if the dance can be danced into or not. A histogram with the frequency of dance abilities will show how many songs on Spotify can be danced into. We do this to visualize a variable used from the dataset.

```{r}
ggplot(spotify_data, aes(x = Danceability)) +
  geom_histogram(binwidth = 0.1, fill = "darkgreen", color = "black", alpha = 0.8) +
  labs(title = "Distribution of Danceability",
       x = "Danceability", y = "Frequency") +
  theme_minimal()

```

## Data Splitting

Now, we will split our Spotify dataset into training and test sets. This is crucial for building and evaluating our models. The training set will be used to train the models, while the test set will be used to evaluate their performance. Setting a seed ensures that the split is reproducible.

```{r}
set.seed(427)

# Split the data into training and test sets
spotify_split <- initial_split(spotify_data, prop = 0.75, strata = Stream)
spotify_train <- training(spotify_split)
spotify_test <- testing(spotify_split)
```

## Lasso Regression

We are more prepping for LASSO. It is a linear regression technique that shrinks some feature to 0. This allows us to select only most important variables. We used these variables in linear regression.

```{r}
# Prepare the data for Lasso
x_train <- model.matrix(Stream ~ Danceability + Energy + Loudness + Speechiness + Acousticness + Duration_min, spotify_train)[,-1]
y_train <- spotify_train$Stream

# Fit Lasso model
lasso_model <- cv.glmnet(x_train, y_train, alpha = 1)

# Best lambda value
best_lambda <- lasso_model$lambda.min

# Coefficients of the model
selected_features <- coef(lasso_model, s = best_lambda)
selected_features
```

## Multiple Linear Regression

```{r}
# Extract selected features
selected_features <- c("Danceability", "Energy", "Loudness", "Speechiness", "Acousticness", "Duration_min")

# Build the formula for the linear model
formula <- as.formula(paste("Stream ~", paste(selected_features, collapse = " + ")))

# Fit the Multiple Linear Regression model
linear_model <- lm(formula, data = spotify_train)
plot(linear_model)

# Summary of the model
summary(linear_model)
plot(linear_model)
# Predict on test data
linear_predictions <- predict(linear_model, newdata = spotify_test)


```

### Model Evaluation

We used variable stream as we are trying to find the number of streams for each song in the test dataset based on the features: Danceability, Energy, Loudness, Speechiness, Acousticness, and Duration_min.

```{r}
# Evaluate the model
linear_rmse <- sqrt(mean((linear_predictions - spotify_test$Stream)^2))
linear_rmse
```

## Gradient Descent

Since we have one model ready, lets compare that with the Gradient Descent. We will choose the best one after we process this and whichever is the best one, we will use to it fit in test set and predict.

```{r}
# Gradient Descent Function
gradient_descent <- function(X, y, learning_rate = 0.01, iterations = 1000) {
  m <- nrow(X)
  n <- ncol(X)
  theta <- matrix(0, n, 1)
  cost_history <- numeric(iterations)
  
  for (i in 1:iterations) {
    predictions <- X %*% theta
    errors <- predictions - y
    gradient <- t(X) %*% errors / m
    theta <- theta - learning_rate * gradient
    cost_history[i] <- sum(errors^2) / (2 * m)
  }
  
  list(theta = theta, cost_history = cost_history)
}

# Prepare the data for gradient descent
selected_features <- c("Danceability", "Energy", "Loudness", "Speechiness", "Acousticness", "Duration_min")
X_train <- as.matrix(cbind(1, spotify_train[, selected_features]))
y_train <- as.matrix(spotify_train$Stream)

# Run gradient descent
result <- gradient_descent(X_train, y_train, learning_rate = 0.01, iterations = 1000)

# Extract the optimized parameters
theta <- result$theta
cost_history <- result$cost_history

# Plot the cost history
plot(cost_history, type = "l", col = "blue", xlab = "Iterations", ylab = "Cost", main = "Cost Function History")
```

### Model Evaluation

We used variable stream as we are trying to find the number of streams for each song in the test dataset based on the features: Danceability, Energy, Loudness, Speechiness, Acousticness, and Duration_min.

```{r}
# Prepare the test data
X_test <- as.matrix(cbind(1, spotify_test[, selected_features]))
y_test <- as.matrix(spotify_test$Stream)

# Make predictions
predictions <- X_test %*% theta

# Evaluate the model
gradient_rmse <- sqrt(mean((predictions - y_test)^2))
gradient_rmse 
```

## Prediction

The linear regression model after LASSO has a slightly lower error compared to the linear gradient model on the training set. This suggests that, on the training data, the linear model fits slightly better.

```{r}
predicted_streams <- predict(linear_model, newdata = spotify_test) 
# Comment out because it is too long
#predicted_streams
```

Here, the numbers 1,2,3,4.... etc indicates the number of rows in the dataset. We could pull up the individual name of track by:

```{r}
results <- data.frame(Track = spotify_test$Track, Predicted_Streams = predicted_streams)

# Display the results
# print(results) Commented out because the results are too long
```

### Plotting the predicted information

Here we plot the information from above. since there are a lot fo entries we will only plot the top 10 to get the gist of the predicted values.

```{r}
results <- data.frame(Track = spotify_test$Track, Predicted_Streams = predicted_streams)

# Select the top 10 tracks based on predicted streams
top_10_results <- results |> arrange(desc(Predicted_Streams)) |> head(10)

# Plot the results
ggplot(top_10_results, aes(x = reorder(Track, -Predicted_Streams), y = Predicted_Streams)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(title = "Top 10 Tracks by Predicted Streams", x = "Track Name", y = "Predicted Streams") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Since we split the data, the full dataset contains only a limited number of songs in the test set, which could lead to inaccurate results. However, the model's behavior remains the same.

##  Resource

Citations: <https://www.kaggle.com/datasets/sanjanchaudhari/spotify-dataset>\
